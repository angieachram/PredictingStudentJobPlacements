{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "ttD4BqYViWsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_features = pd.read_csv(\"/content/Train_Features1.csv\")\n",
        "data_train_target = pd.read_csv(\"/content/Train_Target.csv\")\n",
        "data_test_features = pd.read_csv(\"/content/Test_Features1.csv\")"
      ],
      "metadata": {
        "id": "aeopzs0diXhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "data=pd.merge(data_train_features,data_train_target,on=\"ID\")\n",
        "data.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "categorical_features = ['Gender', 'Board_SSC', 'Board_HSC', 'Stream_HSC',\n",
        "                        'Course_Degree', 'Entrance_Test', 'Specialization_MBA']\n",
        "\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_features:\n",
        "    data[col] = data[col].astype(str).str.strip().str.lower()\n",
        "    data_test_features[col] = data_test_features[col].astype(str).str.strip().str.lower()\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "for col in categorical_features:\n",
        "    le = label_encoders[col]\n",
        "    common_class = le.classes_[0]\n",
        "    data_test_features[col] = data_test_features[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else le.transform([common_class])[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "QLUMsX3UrmE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "MNkQhL1eqAV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = data.corr()\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "id": "PxmshnWOEvRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test_features.head()"
      ],
      "metadata": {
        "id": "4ZJhTg6QqMXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=data[['Marks_Projectwork', 'Percent_SSC','S-TEST*SCORE','Percentile_ET','Percent_MBA','Marks_BOCA','Board_HSC','Board_SSC','Entrance_Test',\n",
        "    'Specialization_MBA']]\n",
        "y_train = data[\"Placement\"]\n",
        "X_test = data_test_features[['Marks_Projectwork','Percent_SSC','S-TEST*SCORE','Percentile_ET','Percent_MBA','Marks_BOCA','Board_HSC','Board_SSC',\n",
        "    'Entrance_Test','Specialization_MBA']]"
      ],
      "metadata": {
        "id": "5H81s0mpijPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_X, val_X, dev_y, val_y = train_test_split(X_train, y_train, test_size = 0.2, random_state = 123, stratify = y_train)"
      ],
      "metadata": {
        "id": "aK4EuGbOpHyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "nv-UfizL9Mds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "0D8TMGpQ9Nc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(dev_X)\n",
        "val_scaled = scaler.transform(val_X)"
      ],
      "metadata": {
        "id": "P1U5KwG09P3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(probability=True, random_state=123)\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10],'gamma': ['scale', 'auto'],'kernel': ['rbf', 'linear'],'class_weight': ['balanced']}\n",
        "\n",
        "grid_search = GridSearchCV(svm, param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_scaled, dev_y)\n",
        "print(\" Best Parameters:\", grid_search.best_params_)\n",
        "svm_best = grid_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "Mp0d45J0-KZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(probability=True, C= 1, class_weight= {0: 1, 1: 5},  kernel='linear',random_state=123)\n",
        "svm_model.fit(X_scaled, dev_y)\n",
        "val_preds = svm_model.predict(val_scaled)\n",
        "\n",
        "print(\"Classification Report on Validation Set:\")\n",
        "print(classification_report(val_y, val_preds))\n",
        "\n",
        "print(\" Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds))\n"
      ],
      "metadata": {
        "id": "41bLPTtQ9SK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model.fit(X_train,y_train)\n",
        "y_test_preds = svm_model.predict(X_test)\n",
        "print(np.unique(y_test_preds, return_counts=True))"
      ],
      "metadata": {
        "id": "sDi-7qDVGoP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission=pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placed\": y_test_preds\n",
        "})\n",
        "submission.to_csv(\"svm_linear.csv\", index=False)\n",
        "print(\" Submission saved: svm_linear.csv\")"
      ],
      "metadata": {
        "id": "GBos1uRIHDlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rinikerlab/GHOST"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JVmO9uCB_a_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GHOST"
      ],
      "metadata": {
        "id": "wlSOZszM_cAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "collapsed": true,
        "id": "VhQjYHDR_dq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import ghostml\n",
        "\n",
        "val_probs = svm_model.predict_proba(val_scaled)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(val_y, val_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\"Optimized Threshold (GHOST): {optimal_thresh:.2f}\")\n",
        "\n",
        "val_preds_thresh = (val_probs > optimal_thresh).astype(int)\n",
        "print(\"Classification Report (with GHOST threshold):\")\n",
        "print(classification_report(val_y, val_preds_thresh))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds_thresh))"
      ],
      "metadata": {
        "id": "K2aCHgAw_9bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Apply optimized threshold\n",
        "val_preds_thresh = (val_probs > 0.68).astype(int)\n",
        "\n",
        "# 5. Evaluate\n",
        "print(\" Classification Report (with GHOST threshold):\")\n",
        "print(classification_report(val_y, val_preds_thresh))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds_thresh))"
      ],
      "metadata": {
        "id": "98KTAYwGAGlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ghostml\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "svm_model = SVC(probability=True, C= 1, class_weight= {0: 1, 1: 5},  kernel='linear',random_state=123)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "train_probs = svm_model.predict_proba(X_train_scaled)[:, 1]\n",
        "\n",
        "thresholds = np.round(np.arange(0.1, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(y_train, train_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\" GHOST-optimized threshold: {optimal_thresh:.2f}\")\n",
        "\n",
        "test_probs = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
        "test_preds = (test_probs >optimal_thresh).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placed\": test_preds\n",
        "})\n",
        "submission.to_csv(\"svm_ghost_linear.csv\", index=False)\n",
        "print(\" Submission saved: svm_ghost_linear.csv\")\n"
      ],
      "metadata": {
        "id": "vHYw2d52BR5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=123)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "smote = SMOTE(random_state=123)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_pca, y_train)\n",
        "\n",
        "svm_smote_pca = SVC(probability=True, C= 1, class_weight= {0: 1, 1: 5},  kernel='linear',random_state=123)\n",
        "svm_smote_pca.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "\n",
        "train_probs = svm_smote_pca.predict_proba(X_train_smote)[:, 1]\n",
        "thresholds = np.round(np.arange(0.1, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(y_train_smote, train_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\" GHOST Threshold (SMOTE+PCA): {optimal_thresh:.2f}\")\n",
        "\n",
        "test_probs = svm_smote_pca.predict_proba(X_test_pca)[:, 1]\n",
        "test_preds = (test_probs > optimal_thresh).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placed\": test_preds\n",
        "})\n",
        "submission.to_csv(\"svm_smote_pca_ghost.csv\", index=False)\n",
        "print(\" Submission saved: svm_smote_pca_ghost.csv\")\n"
      ],
      "metadata": {
        "id": "MyO6jtFsChLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "svm_pca = SVC(probability=True, C= 1, class_weight= {0: 1, 1: 5},  kernel='linear',random_state=123)\n",
        "svm_pca.fit(X_train_pca, y_train)\n",
        "\n",
        "train_probs = svm_pca.predict_proba(X_train_pca)[:, 1]\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(y_train, train_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\" GHOST Threshold (PCA only): {optimal_thresh:.2f}\")\n",
        "\n",
        "test_probs = svm_pca.predict_proba(X_test_pca)[:, 1]\n",
        "test_preds = (test_probs > optimal_thresh).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placed\": test_preds\n",
        "})\n",
        "submission.to_csv(\"svm_pca_ghost.csv\", index=False)\n",
        "print(\" Submission saved: svm_pca_ghost.csv\")\n"
      ],
      "metadata": {
        "id": "R2jeahNoCkhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "YX5nw96OJvII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "EWmO97uaKsSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 5],\n",
        "    'class_weight': [None, {0: 1, 1: 5}, {0: 1, 1: 10}]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=123)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "grid_search.fit(dev_X, dev_y)\n",
        "\n",
        "print(\"Best Params:\", grid_search.best_params_)\n",
        "print(\"Best ROC AUC:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "oxGnvKhOKOQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': [0, 1, 5],\n",
        "    'scale_pos_weight': [1, 5, 10]\n",
        "}\n",
        "\n",
        "xgb_search = RandomizedSearchCV(\n",
        "    estimator=XGBClassifier(random_state=123, use_label_encoder=False, eval_metric='logloss'),\n",
        "    param_distributions=xgb_param_grid,\n",
        "    n_iter=20,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    random_state=123,\n",
        "    verbose=1\n",
        ")\n",
        "xgb_search.fit(X_scaled, dev_y)\n",
        "\n",
        "print(\"Best XGBoost parameters found:\")\n",
        "print(xgb_search.best_params_)\n",
        "print(f\"Best F1 Score from CV: {xgb_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "id": "Pz1tI-b4hMBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(dev_X)\n",
        "val_scaled = scaler.transform(val_X)\n",
        "\n",
        "best_params = xgb_search.best_params_.copy()\n",
        "best_params['random_state'] = 123\n",
        "\n",
        "best_model = XGBClassifier(**best_params)\n",
        "best_model.fit(X_scaled, dev_y)\n",
        "\n",
        "val_preds = best_model.predict(val_scaled)\n",
        "\n",
        "print(\"Classification Report on Validation Set:\")\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(\" Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds))\n"
      ],
      "metadata": {
        "id": "ZnS0RMlwhRmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "best_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "test_probs = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "test_preds = (test_probs > 0.5).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placed\": test_preds\n",
        "})\n",
        "submission.to_csv(\"xgb_baseline_submission.csv\", index=False)\n",
        "print(\" Submission saved: xgb_baseline_submission.csv\")"
      ],
      "metadata": {
        "id": "RVIwnTbDwYrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import ghostml\n",
        "import numpy as np\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(dev_X)\n",
        "val_scaled = scaler.transform(val_X)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=123)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "val_pca = pca.transform(val_scaled)\n",
        "\n",
        "smote = SMOTE(random_state=123)\n",
        "X_smote, y_smote = smote.fit_resample(X_pca, dev_y)\n",
        "\n",
        "best_params = xgb_search.best_params_.copy()\n",
        "best_params['random_state'] = 123\n",
        "xgb_final = XGBClassifier(**best_params)\n",
        "xgb_final.fit(X_smote, y_smote)\n",
        "\n",
        "val_probs = xgb_final.predict_proba(val_pca)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(val_y, val_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(\" Optimized threshold: {optimal_thresh:.2f}\")\n",
        "\n",
        "val_preds_thresh = (val_probs > optimal_thresh).astype(int)\n",
        "print(\" Classification Report with GHOST threshold:\")\n",
        "print(classification_report(val_y, val_preds_thresh))\n",
        "print(\" Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds_thresh))\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_pca, y_train)\n",
        "\n",
        "xgb_final.fit(X_train_smote, y_train_smote)\n",
        "train_probs = xgb_final.predict_proba(X_train_smote)[:, 1]\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(y_train_smote, train_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\"Retrained GHOST Threshold: {optimal_thresh:.2f}\")\n",
        "\n",
        "test_probs = xgb_final.predict_proba(X_test_pca)[:, 1]\n",
        "\n",
        "test_preds = (test_probs > optimal_thresh).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placed\": test_preds\n",
        "})\n",
        "submission.to_csv(\"allsubmission.csv\", index=False)\n",
        "print(\"Submission saved: allsubmission.csv\")\n"
      ],
      "metadata": {
        "id": "Z3kYm8SosQsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(dev_X)\n",
        "val_scaled = scaler.transform(val_X)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=123)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "val_pca = pca.transform(val_scaled)\n",
        "\n",
        "best_params = xgb_search.best_params_.copy()\n",
        "best_params['random_state'] = 123\n",
        "xgb_pca = XGBClassifier(**best_params)\n",
        "xgb_pca.fit(X_pca, dev_y)\n",
        "\n",
        "val_probs = xgb_pca.predict_proba(val_pca)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(val_y, val_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\"Optimized threshold (PCA): {optimal_thresh:.2f}\")\n",
        "\n",
        "val_preds = (val_probs > optimal_thresh).astype(int)\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(confusion_matrix(val_y, val_preds))\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "xgb_pca.fit(X_train_pca, y_train)\n",
        "train_probs = xgb_pca.predict_proba(X_train_pca)[:, 1]\n",
        "\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(y_train, train_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\" Retrained GHOST Threshold: {optimal_thresh:.2f}\")\n",
        "\n",
        "test_probs = xgb_final.predict_proba(X_test_pca)[:, 1]\n",
        "\n",
        "test_preds = (test_probs > optimal_thresh).astype(int)\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placed\": test_preds\n",
        "})\n",
        "submission.to_csv(\"xgb_pca_ghost_submission.csv\", index=False)\n",
        "print(\" Submission saved: xgb_pca_ghost_submission.csv\")\n"
      ],
      "metadata": {
        "id": "hBh-hUU6s5zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=123),\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    scoring='f1',\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "search.fit(X_scaled, dev_y)\n",
        "print(\"Best parameters found:\")\n",
        "print(search.best_params_)\n",
        "print(f\"Best F1 Score from CV: {search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "id": "Pi3wXoUmcjdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled = scaler.fit_transform(dev_X)\n",
        "val_scaled = scaler.transform(val_X)\n",
        "best_model = search.best_estimator_\n",
        "val_preds = best_model.predict(val_scaled)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\" Classification Report on Validation Set:\")\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(\" Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds))\n"
      ],
      "metadata": {
        "id": "Hw7j5HNocurc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_full_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "best_model_full = search.best_estimator_\n",
        "best_model_full.fit(X_full_scaled, y_train)"
      ],
      "metadata": {
        "id": "fExJDrFgdbG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_scaled = scaler.transform(X_test)\n",
        "test_preds = best_model_full.predict(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "EJ69JRKJdch7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    'ID': data_test_features['ID'],\n",
        "    'Placement': test_preds\n",
        "})\n",
        "submission.to_csv(\"rf_submission_randomised_search.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "6bMoIFcndgac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_probs = best_model.predict_proba(val_scaled)[:, 1]\n",
        "import ghostml\n",
        "\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(val_y, val_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\"Optimized threshold (Kappa): {optimal_thresh:.2f}\")"
      ],
      "metadata": {
        "id": "kiC06ANKds8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_preds_ghost = (val_probs > optimal_thresh).astype(int)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\"Classification Report with GHOST threshold:\")\n",
        "print(classification_report(val_y, val_preds_ghost))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds_ghost))"
      ],
      "metadata": {
        "id": "mIIVsTAIdzez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "best_model = search.best_estimator_\n",
        "best_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "test_probs = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "final_preds = (test_probs > optimal_thresh).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placement\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission_final_rf_ghost.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "-DEbP8skfRTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = {0: 1, 1: 9}  # 9,10\n",
        "\n",
        "fr_weighted = RandomForestClassifier(n_estimators=200,max_depth=4,class_weight=weights,random_state=123)\n",
        "scaler=StandardScaler()\n",
        "X_scaled = scaler.fit_transform(dev_X)\n",
        "val_scaled = scaler.transform(val_X)\n",
        "\n",
        "fr_weighted.fit(X_scaled, dev_y)\n",
        "preds = fr_weighted.predict(val_scaled)\n",
        "\n",
        "print(classification_report(val_y, preds))\n",
        "print(confusion_matrix(val_y, preds))"
      ],
      "metadata": {
        "id": "Uzdk6kewNFXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_dev_scaled = scaler.fit_transform(dev_X)\n",
        "X_val_scaled = scaler.transform(val_X)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=123)\n",
        "X_dev_pca = pca.fit_transform(X_dev_scaled)\n",
        "X_val_pca = pca.transform(X_val_scaled)\n",
        "\n",
        "best_model = search.best_estimator_\n",
        "best_model.fit(X_dev_pca, dev_y)\n",
        "\n",
        "val_preds = best_model.predict(X_val_pca)\n",
        "\n",
        "print(\"Classification Report (PCA, no GHOST):\")\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds))\n"
      ],
      "metadata": {
        "id": "R7Bmex-JfyfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=123)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "best_model = search.best_estimator_\n",
        "best_model.fit(X_train_pca, y_train)\n",
        "\n",
        "test_preds = best_model.predict(X_test_pca)\n",
        "\n",
        "submission_pca = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placement\": test_preds\n",
        "})\n",
        "submission_pca.to_csv(\"submission_rf_pca.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "muDK8XosfynJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rinikerlab/GHOST"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6SfWx1vtPILO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GHOST"
      ],
      "metadata": {
        "id": "pSUPSxHRPQbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "collapsed": true,
        "id": "YhIqMkEfPSTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ghostml"
      ],
      "metadata": {
        "id": "DKitXwqVPT4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_probs = fr_weighted.predict_proba(X_scaled)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(dev_y, train_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\"Optimized threshold: {optimal_thresh:.2f}\")\n",
        "val_probs = fr_weighted.predict_proba(val_scaled)[:, 1]\n",
        "val_preds = (val_probs > optimal_thresh).astype(int)\n",
        "\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(confusion_matrix(val_y, val_preds))\n"
      ],
      "metadata": {
        "id": "YWUZ6YUbPhrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "weights = {0: 1, 1: 9}\n",
        "model = RandomForestClassifier(n_estimators=200, max_depth=4, class_weight=weights, random_state=123)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "train_probs = model.predict_proba(X_train_scaled)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.6, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(\n",
        "    y_train, train_probs, thresholds, ThOpt_metrics='Kappa'\n",
        ")\n",
        "print(f\"Optimized threshold from full training data: {optimal_thresh:.2f}\")\n",
        "\n",
        "test_probs = model.predict_proba(X_test_scaled)[:, 1]\n",
        "final_preds = (test_probs > optimal_thresh).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placement\": final_preds\n",
        "})\n",
        "submission.to_csv(\"random_forest_submission.csv\", index=False)\n",
        "print(\"Submission saved as 'random_forest_submission.csv'\")"
      ],
      "metadata": {
        "id": "F2mL8kMFRR1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import ghostml\n",
        "import numpy as np\n",
        "\n",
        "scaler = StandardScaler()\n",
        "dev_scaled = scaler.fit_transform(dev_X)\n",
        "val_scaled = scaler.transform(val_X)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=123)\n",
        "dev_pca = pca.fit_transform(dev_scaled)\n",
        "val_pca = pca.transform(val_scaled)\n",
        "\n",
        "weights = {0: 1, 1: 9}\n",
        "model = RandomForestClassifier(n_estimators=200, max_depth=2, class_weight=weights, random_state=123)\n",
        "model.fit(dev_pca, dev_y)\n",
        "\n",
        "train_probs = model.predict_proba(dev_pca)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.6, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(\n",
        "    dev_y, train_probs, thresholds, ThOpt_metrics='Kappa'\n",
        ")\n",
        "print(f\"Optimized threshold: {optimal_thresh:.2f}\")\n",
        "\n",
        "val_probs = model.predict_proba(val_pca)[:, 1]\n",
        "val_preds = (val_probs > optimal_thresh).astype(int)\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(val_y, val_preds))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds))\n"
      ],
      "metadata": {
        "id": "JsRxOJPkSzpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import ghostml\n",
        "\n",
        "X_train = data.drop(\"Placement\", axis=1)\n",
        "y_train = data[\"Placement\"]\n",
        "X_test = data_test_features.drop(\"ID\", axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=123)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "weights = {0: 1, 1: 9}\n",
        "model = RandomForestClassifier(n_estimators=200, max_depth=2, class_weight=weights, random_state=123)\n",
        "model.fit(X_train_pca, y_train)\n",
        "\n",
        "train_probs = model.predict_proba(X_train_pca)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.6, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(\n",
        "    y_train, train_probs, thresholds, ThOpt_metrics='Kappa'\n",
        ")\n",
        "print(f\"Optimized threshold after PCA: {optimal_thresh:.2f}\")\n",
        "\n",
        "test_probs = model.predict_proba(X_test_pca)[:, 1]\n",
        "final_preds = (test_probs > optimal_thresh).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placement\": final_preds\n",
        "})\n",
        "submission.to_csv(\"rf_pca_submission1.csv\", index=False)\n",
        "print(\" PCA-enhanced submission saved as 'rf_pca_submission1.csv'\")"
      ],
      "metadata": {
        "id": "J285w_95SnNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=123)\n",
        "X_resampled, y_resampled = sm.fit_resample(dev_X, dev_y)\n",
        "X_scaled = scaler.fit_transform(X_resampled)\n",
        "val_scaled = scaler.transform(val_X)\n",
        "\n",
        "fr_weighted.fit(X_scaled, y_resampled)\n",
        "preds = fr_weighted.predict(val_scaled)\n",
        "\n",
        "print(classification_report(val_y, preds))\n",
        "print(confusion_matrix(val_y, preds))"
      ],
      "metadata": {
        "id": "G9mpqIXMOWp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import ghostml\n",
        "\n",
        "sm = SMOTE(random_state=123)\n",
        "X_resampled, y_resampled = sm.fit_resample(dev_X, dev_y)\n",
        "\n",
        "X_scaled = scale(X_resampled)\n",
        "pca = PCA(n_components=0.95, random_state=123)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "rf=RandomForestClassifier(n_estimators=200,max_depth=6,class_weight={0: 1, 1: 6},random_state=123)\n",
        "rf.fit(X_pca, y_resampled)\n",
        "\n",
        "train_probs = rf.predict_proba(X_pca)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(y_resampled, train_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\"Optimized threshold: {optimal_thresh:.2f}\")\n",
        "\n",
        "val_scaled = scale(val_X)\n",
        "val_pca = pca.transform(val_scaled)\n",
        "val_probs = rf.predict_proba(val_pca)[:, 1]\n",
        "val_preds = (val_probs > optimal_thresh).astype(int)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(\" Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds))\n"
      ],
      "metadata": {
        "id": "4tDvQJN6JxSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "jfJ7AmdHt3Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "7tUUm8ATt5jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=123))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'lr__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'lr__penalty': ['l1', 'l2'],\n",
        "    'lr__solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=123)\n",
        "\n",
        "grid = GridSearchCV(pipe, param_grid=param_grid, cv=cv, scoring=scorer, n_jobs=-1)\n",
        "grid.fit(dev_X, dev_y)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best macro F1 score:\", grid.best_score_)\n"
      ],
      "metadata": {
        "id": "brxUo7aVvOPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rinikerlab/GHOST"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IPpadjly2uX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "weights = {0: 1, 1: 7}\n",
        "\n",
        "lr_weighted = LogisticRegression(C=1,penalty='l2',solver='saga',class_weight=weights,random_state=123,max_iter=1000)\n",
        "scaler=StandardScaler()\n",
        "X_scaled = scaler.fit_transform(dev_X)\n",
        "val_scaled = scaler.transform(val_X)\n",
        "\n",
        "lr_weighted.fit(X_scaled, dev_y)\n",
        "preds = lr_weighted.predict(val_scaled)\n",
        "\n",
        "print(classification_report(val_y, preds))\n",
        "print(confusion_matrix(val_y, preds))\n"
      ],
      "metadata": {
        "id": "FRyj9VKwukYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "lr_final = LogisticRegression(C=1, penalty='l2', solver='saga',  class_weight={0: 1, 1: 7}, random_state=123,max_iter=1000)\n",
        "lr_final.fit(X_train_scaled, y_train)\n",
        "\n",
        "test_preds = lr_final.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "z0O3WbpH0PW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placement\": test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission_logreg_iter1000.csv\", index=False)\n",
        "print(\" Submission file saved as 'submission_logreg_weight7.csv'\")"
      ],
      "metadata": {
        "id": "IS_4M7P41hwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import ghostml\n",
        "import numpy as np\n",
        "\n",
        "X_scaled = scale(dev_X)\n",
        "pca = PCA(n_components=0.95, random_state=123)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "model = LogisticRegression(C=1, solver='saga', random_state=123, class_weight={0: 1, 1: 7},max_iter=1000)\n",
        "model.fit(X_pca, dev_y)\n",
        "\n",
        "val_scaled = scale(val_X)\n",
        "val_pca = pca.transform(val_scaled)\n",
        "val_probs = model.predict_proba(val_pca)[:, 1]\n",
        "val_preds = (val_probs > 0.6).astype(int)\n",
        "\n",
        "print(\"Classification Report on Validation Set:\")\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(val_y, val_preds))\n"
      ],
      "metadata": {
        "id": "bJPAnCIh8Jod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rinikerlab/GHOST"
      ],
      "metadata": {
        "id": "Q7T2YeIjciJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GHOST"
      ],
      "metadata": {
        "id": "VRBBZKONcjWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "collapsed": true,
        "id": "7GFLlKXMcmkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import ghostml\n",
        "X_train = data.drop([\"Placement\"], axis=1)\n",
        "y_train = data[\"Placement\"]\n",
        "X_test = data_test_features.drop([\"ID\"], axis=1)\n",
        "\n",
        "X_scaled = scale(X_train)\n",
        "pca = PCA(n_components=0.95, random_state=123)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "model = LogisticRegression(C=1, solver='saga',random_state=123, class_weight={0: 1, 1: 7},max_iter=1000)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "cv_scores = cross_val_score(model, X_pca, y_train, cv=cv, scoring='roc_auc')\n",
        "print(f\"Cross-validation AUC scores: {cv_scores}\")\n",
        "print(f\"Mean AUC score: {np.mean(cv_scores):.4f}\")\n",
        "model.fit(X_pca, y_train)\n",
        "\n",
        "train_probs = model.predict_proba(X_pca)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(\n",
        "    y_train, train_probs, thresholds, ThOpt_metrics='Kappa'\n",
        ")\n",
        "print(f\"Optimized threshold: {optimal_thresh:.2f}\")\n",
        "\n",
        "X_test_scaled = scale(X_test)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "test_probs = model.predict_proba(X_test_pca)[:, 1]\n",
        "final_preds = (test_probs > 0.6).astype(int)\n",
        "submission = pd.DataFrame({\n",
        "    'ID': data_test_features['ID'],\n",
        "    'Placement': final_preds\n",
        "})\n",
        "submission.to_csv(\"logistic_submission.csv\", index=False)\n",
        "print(\" Logistic Regression submission saved as 'logistic_submission.csv'\")"
      ],
      "metadata": {
        "id": "bg-QsBtg9DEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA with SMOTE and XGBoost"
      ],
      "metadata": {
        "id": "s1yyFnS6TLum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "pca = PCA()\n",
        "X_reduced_train = pca.fit_transform(scale(dev_X))"
      ],
      "metadata": {
        "id": "u1sZwFb6TNcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=123)"
      ],
      "metadata": {
        "id": "dvxx-H61TYIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
        "model1 = XGBClassifier(n_estimators=300, learning_rate=0.2, max_depth=3, random_state=123, scale_pos_weight=10)\n",
        "model1.fit(X_reduced_train, dev_y)"
      ],
      "metadata": {
        "id": "OWbJXnsvTcMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(model1, X_reduced_train, dev_y, cv=cv, scoring='f1_macro')"
      ],
      "metadata": {
        "id": "TM1S1P3hWBmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cross-validation F1 scores:\", scores)\n",
        "print(\"Mean F1 score:\", np.mean(scores))"
      ],
      "metadata": {
        "id": "cwP9abXyWFrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "id": "9g-Jn5T8XXyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "sm = SMOTE(random_state=123)\n",
        "X_resampled, y_resampled = sm.fit_resample(dev_X, dev_y)\n",
        "\n",
        "X_resampled_scaled = scale(X_resampled)\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_resampled_scaled)\n",
        "\n",
        "model = XGBClassifier(n_estimators=300, learning_rate=0.2, max_depth=3, random_state=123,scale_pos_weight=1)# after SMOTE, classes are balanced\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=123)\n",
        "scores = cross_val_score(model, X_pca, y_resampled, scoring='f1_macro', cv=cv)\n",
        "print(\"Cross-validation F1 scores:\", scores)\n",
        "print(\"Mean F1 score:\", np.mean(scores))"
      ],
      "metadata": {
        "id": "6Q6QZHjQXZa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "X_resampled_scaled = scale(X_resampled)\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca_final = pca.fit_transform(X_resampled_scaled)\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.2,\n",
        "    max_depth=3,\n",
        "    random_state=123,\n",
        "    scale_pos_weight=1\n",
        ")\n",
        "model.fit(X_pca_final, y_resampled)\n",
        "\n",
        "X_test_scaled = scale(X_test)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# 5. Predict\n",
        "y_test_preds = model.predict(X_test_pca)\n",
        "print(np.unique(y_test_preds, return_counts=True))"
      ],
      "metadata": {
        "id": "Q6OHr1lyYxwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test_preds)"
      ],
      "metadata": {
        "id": "hfMlCjkUYz9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placement\": y_test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission_xgboost.csv\", index=False)"
      ],
      "metadata": {
        "id": "Qqu8x-GFZSE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting try to rerun"
      ],
      "metadata": {
        "id": "duMKVixM2Ruc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score"
      ],
      "metadata": {
        "id": "ukmZw_aiio-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "model = GradientBoostingClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 6,7, 9],\n",
        "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1')\n",
        "grid_search.fit(dev_X, dev_y)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "xO7eoOsh3R-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=dev_y)\n",
        "model=GradientBoostingClassifier(n_estimators=200, learning_rate=0.2, max_depth=6,random_state=123)\n",
        "cv_scores = cross_val_score(model, dev_X, dev_y, cv=10, scoring='f1_macro')\n",
        "model.fit(dev_X, dev_y,sample_weight=sample_weights,eval_set=[(val_X, val_y)])\n",
        "val_preds=model.predict(val_X)\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(confusion_matrix(val_y, val_preds))"
      ],
      "metadata": {
        "id": "gyvtYznwi4Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "custom_weights = np.where(dev_y == 0, 1, 5)\n",
        "\n",
        "model = GradientBoostingClassifier(n_estimators=200, learning_rate=0.2, max_depth=6, random_state=123)\n",
        "cv_scores = cross_val_score(model, dev_X, dev_y, cv=10, scoring='f1_macro')\n",
        "model.fit(dev_X, dev_y,sample_weight=custom_weights)\n",
        "val_preds=model.predict(val_X)\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(confusion_matrix(val_y, val_preds))"
      ],
      "metadata": {
        "id": "vzVmSSHLZYVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train)\n",
        "y_test_preds = model.predict(X_test)\n",
        "print(y_test_preds)"
      ],
      "metadata": {
        "id": "sf6AQpoJbJIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest and SMOTE"
      ],
      "metadata": {
        "id": "GsHfeJrP2KKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators = 200, random_state = 123)\n",
        "rf.fit(dev_X, dev_y)\n",
        "val_preds=rf.predict(val_X)\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(confusion_matrix(val_y, val_preds))"
      ],
      "metadata": {
        "id": "xxnyEmyzrQjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote=SMOTE()\n",
        "X_resampled, y_resampled = smote.fit_resample(dev_X, dev_y)\n",
        "model2=RandomForestClassifier(max_depth=6,n_estimators=100,random_state=123,oob_score=True)\n",
        "model2.fit(X_resampled,y_resampled)"
      ],
      "metadata": {
        "id": "1iHY7iFgrV7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "test_probs=model2.predict_proba(val_X)[:,1]\n",
        "metrics.roc_auc_score(val_y,test_probs)"
      ],
      "metadata": {
        "id": "NarNXhznr0cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model2.predict(val_X)\n",
        "print(metrics.classification_report(val_y,y_pred))"
      ],
      "metadata": {
        "id": "kiZGmipksKjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking"
      ],
      "metadata": {
        "id": "X6n2teWM2amE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "smote=SMOTE()\n",
        "X_resampled, y_resampled = smote.fit_resample(dev_X, dev_y)\n",
        "estimators = [('rf', RandomForestClassifier(max_depth=6,n_estimators=100,random_state=123,oob_score=True) ),\n",
        "              ('gb', GradientBoostingClassifier(n_estimators=200, learning_rate=0.2, max_depth=6, random_state=123))]\n",
        "\n",
        "clf = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression(), cv = 10)\n",
        "clf.fit(X_resampled, y_resampled)"
      ],
      "metadata": {
        "id": "8WhlnCvOpklU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs=clf.predict_proba(val_X)[:,1]\n",
        "metrics.roc_auc_score(val_y,test_probs)"
      ],
      "metadata": {
        "id": "Fiu9nON1s1u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=clf.predict(val_X)\n",
        "print(metrics.classification_report(val_y,y_pred))"
      ],
      "metadata": {
        "id": "jVGhkU00tHQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "t7oZiXHo2Eb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "model1 = XGBClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 6,7, 9],\n",
        "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model1, param_grid=param_grid, cv=10, scoring='f1_macro')\n",
        "grid_search.fit(dev_X, dev_y)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "USfbjbZogIp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "model1 = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=7, random_state=123, scale_pos_weight=9)\n",
        "model1.fit(dev_X, dev_y)\n",
        "val_preds=model1.predict(val_X)\n",
        "print(classification_report(val_y, val_preds))\n",
        "print(confusion_matrix(val_y, val_preds))"
      ],
      "metadata": {
        "id": "rTKh8fMVTSg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(X_train,y_train)\n",
        "y_test_preds = model1.predict(X_test)\n",
        "print(np.unique(y_test_preds, return_counts=True))"
      ],
      "metadata": {
        "id": "TJ3Fp20YxtPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test_preds) #0.33333"
      ],
      "metadata": {
        "id": "89kPp_kDz4yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placement\": y_test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"xg.csv\", index=False)"
      ],
      "metadata": {
        "id": "jAzAQNcnKFkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model00=XGBClassifier(n_estimators=300, learning_rate=0.2, max_depth=3, random_state=123, scale_pos_weight=1)\n",
        "model00.fit(dev_X, dev_y)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uZ4lGpfFZl35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred=model00.predict(val_X)\n",
        "print(classification_report(val_y,y_pred))"
      ],
      "metadata": {
        "id": "87kA6lDVaOqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model00.fit(X_train,y_train)\n",
        "y_test_preds = model00.predict(X_test)\n",
        "print(np.unique(y_test_preds, return_counts=True))"
      ],
      "metadata": {
        "id": "AwztTzZZa7h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test_preds) #also 0.33333"
      ],
      "metadata": {
        "id": "A4A8BrDVcYnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    \"ID\": data_test_features[\"ID\"],\n",
        "    \"Placement\": y_test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission1.csv\", index=False)"
      ],
      "metadata": {
        "id": "y93DVF0nz_6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_final = GridSearchCV(estimator=model1, param_grid=param_grid, cv=10, scoring='f1_macro')\n",
        "grid_search_final.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search_final.best_estimator_\n",
        "\n",
        "y_test_preds = best_model.predict(X_test)\n",
        "print(np.unique(y_test_preds, return_counts=True))"
      ],
      "metadata": {
        "id": "rchqHGpbveeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test_preds)"
      ],
      "metadata": {
        "id": "g7fiZBKewxS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GHOST and XGBoost"
      ],
      "metadata": {
        "id": "nlwR5MVeesan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "model_xgb = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=7, random_state=123, scale_pos_weight=9)\n",
        "model_xgb.fit(dev_X, dev_y)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "k1ek-2aIjlRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_prob = model_xgb.predict_proba(dev_X)[:, 1]"
      ],
      "metadata": {
        "id": "7CfUbmz8mag8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = thresholds = np.round(np.arange(0.21, 0.36, 0.01), 2)\n",
        "threshold1 = ghostml.optimize_threshold_from_predictions(\n",
        "    dev_y, train_prob, thresholds, ThOpt_metrics='Kappa'\n",
        ")\n",
        "\n",
        "print(f\"Optimized threshold: {threshold1}\")"
      ],
      "metadata": {
        "id": "x5G1tbBGlVgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_probs = model_xgb.predict_proba(val_X)[:, 1]\n",
        "best_preds = (val_probs > threshold1).astype(int)"
      ],
      "metadata": {
        "id": "cbBYB9ABmgjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_metrics(labels_test, test_probs, threshold=0.5):\n",
        "    scores = [1 if x >= threshold else 0 for x in test_probs]\n",
        "    auc = metrics.roc_auc_score(labels_test, test_probs)\n",
        "    kappa = metrics.cohen_kappa_score(labels_test, scores)\n",
        "    confusion = metrics.confusion_matrix(labels_test, scores, labels=list(set(labels_test)))\n",
        "    print(f'thresh: {threshold:.2f}, kappa: {kappa:.3f}, AUC test: {auc:.3f}')\n",
        "    print(confusion)\n",
        "    print(metrics.classification_report(labels_test, scores))\n",
        "    return\n",
        "calc_metrics(val_y, val_probs, threshold=threshold1)"
      ],
      "metadata": {
        "id": "E9FQf2wylQ3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "cv_scores = cross_val_score(model_xgb, X_resampled, y_resampled, cv=cv, scoring='roc_auc')\n",
        "\n",
        "print(f\"Cross-validation AUC scores: {cv_scores}\")\n",
        "print(f\"Mean AUC score: {np.mean(cv_scores)}\")\n"
      ],
      "metadata": {
        "id": "Rxg3nQzJpUwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_final = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=7, random_state=123, scale_pos_weight=9)\n",
        "model_final.fit(X_train, y_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XFbyPrvzgX2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs = model_final.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "EYnSNxzughW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_preds = (test_probs > threshold1).astype(int)\n",
        "\n",
        "print(np.unique(final_preds, return_counts=True))"
      ],
      "metadata": {
        "id": "zTSwalzMgj25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = data_test_features[[\"ID\"]].copy()\n",
        "submission[\"Placement\"] = final_preds\n",
        "submission.to_csv(\"ghost_xg.csv\", index=False)"
      ],
      "metadata": {
        "id": "lmfBzx3EgmMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Score"
      ],
      "metadata": {
        "id": "3JiLpLr6iUZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, cohen_kappa_score\n",
        "import ghostml\n",
        "\n",
        "sm = SMOTE(random_state=123)\n",
        "X_resampled, y_resampled = sm.fit_resample(dev_X, dev_y)\n",
        "\n",
        "X_scaled = scale(X_resampled)\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "model = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=7, random_state=123, scale_pos_weight=9)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "cv_scores = cross_val_score(model, X_pca, y_resampled, cv=cv, scoring='roc_auc')\n",
        "print(f\"Cross-validation AUC scores: {cv_scores}\")\n",
        "print(f\"Mean AUC score: {np.mean(cv_scores)}\")\n",
        "\n",
        "model.fit(X_pca, y_resampled)\n",
        "\n",
        "train_probs = model.predict_proba(X_pca)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(y_resampled, train_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\"Optimized threshold: {optimal_thresh}\")\n",
        "\n",
        "X_test_scaled = scale(val_X)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "test_probs = model.predict_proba(X_test_pca)[:, 1]\n",
        "final_preds = (test_probs > optimal_thresh).astype(int)\n",
        "\n",
        "print(classification_report(val_y, final_preds))\n",
        "print(confusion_matrix(val_y, final_preds))"
      ],
      "metadata": {
        "id": "Mji0m_jvfkxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, cohen_kappa_score\n",
        "import ghostml\n",
        "\n",
        "\n",
        "sm = SMOTE(random_state=123)\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "X_scaled = scale(X_resampled)\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "model = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=7, random_state=123, scale_pos_weight=9)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "cv_scores = cross_val_score(model, X_pca, y_resampled, cv=cv, scoring='roc_auc')\n",
        "print(f\"Cross-validation AUC scores: {cv_scores}\")\n",
        "print(f\"Mean AUC score: {np.mean(cv_scores)}\")\n",
        "\n",
        "model.fit(X_pca, y_resampled)\n",
        "\n",
        "train_probs = model.predict_proba(X_pca)[:, 1]\n",
        "thresholds = np.round(np.arange(0.2, 0.5, 0.01), 2)\n",
        "optimal_thresh = ghostml.optimize_threshold_from_predictions(y_resampled, train_probs, thresholds, ThOpt_metrics='Kappa')\n",
        "print(f\"Optimized threshold: {optimal_thresh}\")\n",
        "\n",
        "X_test_scaled = scale(X_test)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "test_probs = model.predict_proba(X_test_pca)[:, 1]\n",
        "final_preds = (test_probs > optimal_thresh).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'ID': data_test_features['ID'],\n",
        "    'Placement': final_preds\n",
        "})\n",
        "submission.to_csv(\"submission3.csv\", index=False)"
      ],
      "metadata": {
        "id": "u4FfrHeFhUF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Light GBM"
      ],
      "metadata": {
        "id": "SXQuTSoV2jOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "id": "7f3DcHXkldn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "gUk16qnh3ar0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model_lgbm = lgb.LGBMClassifier(n_estimators=300,learning_rate=0.2,max_depth=6,random_state=123,scale_pos_weight=5)\n",
        "\n",
        "model_lgbm.fit(dev_X, dev_y)\n",
        "\n",
        "test_preds = model_lgbm.predict(val_X)\n",
        "\n",
        "print(classification_report(val_y, test_preds))\n",
        "print(confusion_matrix(val_y, test_preds))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JoLyV91e3w6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = lgb.LGBMClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 6,7, 9],\n",
        "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model2, param_grid=param_grid, cv=10, scoring='f1_macro')\n",
        "grid_search.fit(dev_X, dev_y)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jsQbx0IV2wFI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}